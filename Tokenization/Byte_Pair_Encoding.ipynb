{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This section covers a more sophisticated tokenization scheme based on a concept called byte pair encoding (BPE).\n",
        "The BPE tokenizer covered in this section was used to train LLMs such as GPT-2, GPT-3, and the original model used in ChatGPT."
      ],
      "metadata": {
        "id": "L-UCA_LNovLW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2f_TM9wclioT"
      },
      "outputs": [],
      "source": [
        "# https://github.com/openai/tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiktoken (OpenAI’s GPT-4 / GPT-4o / GPT-4.5)\n",
        "# GPT-4 and GPT-4o use tiktoken, OpenAI’s efficient tokenizer.\n",
        "\n",
        "# Based on byte-level BPE, but highly optimized for speed & memory.\n",
        "\n",
        "# Backward-compatible with GPT-3 vocabulary but faster.\n"
      ],
      "metadata": {
        "id": "0S4b5qx4ozrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XOj7eLApWWG",
        "outputId": "9188149a-cf41-4222-c0c2-916555691413"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 > Word Based Tokenizer.\n",
        "# 2 > Sub-Word Based Tokenizer.\n",
        "# 3 > Charecter Wised Tokenizer."
      ],
      "metadata": {
        "id": "MRighVx-pWry"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgYm9Oxxpp3i",
        "outputId": "a11e1197-a4e7-4286-edfd-0bb9e088ab05"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The usage of this tokenizer is similar to SimpleTokenizerV2 we implemented previously via an encode method: https://github.com/PrashantTakale369/Transformer-Basics/blob/b0eb0d70b16f09b11f4c5e8bd99e803c8e51771e/Tokanizer/Tokanizer.ipynb"
      ],
      "metadata": {
        "id": "kOlrCJfn2wEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "ZX3CCHWg2p-T"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> My name is Prashant someunknownPlace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--RulILQ2sQo",
        "outputId": "2f782539-8f75-42bb-82c7-65499e100661"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 2011, 1438, 318, 1736, 1077, 415, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then convert the token IDs back into text using the decode method, similar to our SimpleTokenizerV2 earlier:\n",
        "https://github.com/PrashantTakale369/Transformer-Basics/blob/b0eb0d70b16f09b11f4c5e8bd99e803c8e51771e/Tokanizer/Tokanizer.ipynb"
      ],
      "metadata": {
        "id": "6-r0M2oU3HAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpxrTvUV3Dcz",
        "outputId": "4845f11a-9397-4789-abf0-c27adf5037ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> My name is Prashant someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In fact, the BPE tokenizer, which was used to train models such as GPT-2, GPT-3, and the original model used in ChatGPT, has a total vocabulary size of 50,257, with <|endoftext|> being assigned the largest token ID."
      ],
      "metadata": {
        "id": "pNPkTr0I4qSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, the BPE tokenizer above encodes and decodes unknown words, such as \"someunknownPlace\" correctly.\n",
        "The BPE tokenizer can handle any unknown word. How does it achieve this without using <|unk|> tokens?"
      ],
      "metadata": {
        "id": "lFFWZNA74u_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lets Try on Diff meningless word **"
      ],
      "metadata": {
        "id": "GI5O0qbk40du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"jjnd difn\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDoGbS8j4q9T",
        "outputId": "840b85b3-be56-4d56-b992-dec7e5e210a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[41098, 358, 288, 361, 77]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ufe_EEa48x9",
        "outputId": "a16e1190-1b3d-4873-dfea-066ba914b0d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jjnd difn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4eSgq0U4__Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}